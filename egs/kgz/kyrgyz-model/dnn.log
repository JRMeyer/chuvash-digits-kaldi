
###### BEGIN LANGUAGE INFO ######
lang= libri-org
num_targets= 856
data_dir= data/libri-org/train
ali_dir= exp/libri-org/tri_ali
egs_dir= exp/libri-org/nnet3/egs
###### END LANGUAGE INFO ######


###### BEGIN LANGUAGE INFO ######
lang= libri-org
num_targets= 856
data_dir= data/libri-org/train
ali_dir= exp/libri-org/tri_ali
egs_dir= exp/libri-org/nnet3/egs
###### END LANGUAGE INFO ######

### ============================ ###
### CREATE CONFIG FILES FOR NNET ###
### ============================ ###
feat-to-dim scp:data/libri-org/train/feats.scp - 
nnet3-init exp/nnet3/multitask/configs//ref.config exp/nnet3/multitask/configs//ref.raw 
LOG (nnet3-init[5.3.243~1-e4cd1]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/multitask/configs//ref.raw
nnet3-info "nnet3-copy --edits='rename-node old-name=output-0 new-name=output' exp/nnet3/multitask/configs//ref.raw - |" 
nnet3-copy '--edits=rename-node old-name=output-0 new-name=output' exp/nnet3/multitask/configs//ref.raw - 
LOG (nnet3-copy[5.3.243~1-e4cd1]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3/multitask/configs//ref.raw to -
nnet3-init exp/nnet3/multitask/configs//ref.config exp/nnet3/multitask/configs//ref.raw 
LOG (nnet3-init[5.3.243~1-e4cd1]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/multitask/configs//ref.raw
nnet3-info "nnet3-copy --edits='rename-node old-name=output-0 new-name=output' exp/nnet3/multitask/configs//ref.raw - |" 
nnet3-copy '--edits=rename-node old-name=output-0 new-name=output' exp/nnet3/multitask/configs//ref.raw - 
LOG (nnet3-copy[5.3.243~1-e4cd1]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3/multitask/configs//ref.raw to -
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/multitask/configs/network.xconfig --config-dir exp/nnet3/multitask/configs/ --nnet-edits=rename-node old-name=output-0 new-name=output
### ================== ###
### MAKE NNET3 EGS DIR ###
### ================== ###
### MAKE SEPARATE EGS DIR PER LANGUAGE ###
local/nnet3/prepare_multilingual_egs.sh --cmd utils/run.pl --cmvn-opts --norm-means=false --norm-vars=false --left-context 16 --right-context 12 2 data/libri-org/train data/libri-org/train exp/libri-org/tri_ali exp/libri-org/tri_ali exp/libri-org/nnet3/egs exp/libri-org/nnet3/egs tree tree
local/nnet3/prepare_multilingual_egs.sh --cmd utils/run.pl --cmvn-opts --norm-means=false --norm-vars=false --left-context 16 --right-context 12 2 data/libri-org/train data/libri-org/train exp/libri-org/tri_ali exp/libri-org/tri_ali exp/libri-org/nnet3/egs exp/libri-org/nnet3/egs tree tree
2
data/libri-org/train data/libri-org/train exp/libri-org/tri_ali exp/libri-org/tri_ali exp/libri-org/nnet3/egs exp/libri-org/nnet3/egs tree tree
local/nnet3/prepare_multilingual_egs.sh: num_targets_list= (tree tree)
local/nnet3/prepare_multilingual_egs.sh: Generate separate egs directory per language for multilingual training.
online_ivector_dir =
local/nnet3/prepare_multilingual_egs.sh: Generate egs for exp/libri-org/tri_ali
local/nnet3/prepare_multilingual_egs.sh: calling get_egs.sh
steps/nnet3/get_egs.sh --cmvn-opts --norm-means=false --norm-vars=false --left-context 16 --right-context 12 --num-targets tree --samples-per-iter 400000 --stage 0 --cmd utils/run.pl --generate-egs-scp true data/libri-org/train exp/libri-org/tri_ali exp/libri-org/nnet3/egs
steps/nnet3/get_egs.sh data/libri-org/train exp/libri-org/tri_ali exp/libri-org/nnet3/egs
steps/nnet3/get_egs.sh: num_targets = tree
steps/nnet3/get_egs.sh: Found 1400 utterances in data/libri-org/train/utt2spk
steps/nnet3/get_egs.sh: save list of validation utterances to exp/libri-org/nnet3/egs/valid_uttlist
steps/nnet3/get_egs.sh: save list of train utterances to exp/libri-org/nnet3/egs/train_uttlist
steps/nnet3/get_egs.sh: feature type is raw
steps/nnet3/get_egs.sh: working out number of frames of training data in data/libri-org/train
utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files
utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration
wav-to-duration scp:data/libri-org/train/wav.scp ark,t:data/libri-org/train/utt2dur 
LOG (wav-to-duration[5.3.243~1-e4cd1]:main():wav-to-duration.cc:92) Printed duration for 1400 audio files.
LOG (wav-to-duration[5.3.243~1-e4cd1]:main():wav-to-duration.cc:94) Mean duration was 12.5228, min and max durations were 1.87, 17.275
utils/data/get_utt2dur.sh: computed data/libri-org/train/utt2dur
feat-to-len scp:data/libri-org/train/feats.scp ark,t:- 
#### ERROR HERE! ####
steps/nnet3/get_egs.sh: found 1753193 frames of training data
steps/nnet3/get_egs.sh: working out feature dim
steps/nnet3/get_egs.sh: found 1753193 frames in exp/libri-org/nnet3/egs/info/num_frames
steps/nnet3/get_egs.sh: found feat_dim=13 in exp/libri-org/nnet3/egs/info/feat_dim
*** steps/nnet3/get_egs.sh: warning: the --frames-per-eg is too large to generate one archive with
*** as many as --samples-per-iter egs in it.  Consider reducing --frames-per-eg.
steps/nnet3/get_egs.sh: creating 1 archives, each with 219149 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (16,12)
steps/nnet3/get_egs.sh: copying all train data alignments into exp/libri-org/nnet3/egs/ali.scp
copy-int-vector ark:- ark,scp:exp/libri-org/nnet3/egs/ali.ark,exp/libri-org/nnet3/egs/ali.scp 
LOG (copy-int-vector[5.3.243~1-e4cd1]:main():copy-int-vector.cc:83) Copied 1400 vectors of int32.
steps/nnet3/get_egs.sh: num_pdfs= 856
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
copy-feats 'ark,s,cs:utils/filter_scp.pl exp/libri-org/nnet3/egs/train_uttlist data/libri-org/train/feats.scp | apply-cmvn --norm-means=false --norm-vars=false --utt2spk=ark:data/libri-org/train/utt2spk scp:data/libri-org/train/cmvn.scp scp:- ark:- |' ark,t:exp/libri-org/nnet3/egs/train_feats.txt 
apply-cmvn --norm-means=false --norm-vars=false --utt2spk=ark:data/libri-org/train/utt2spk scp:data/libri-org/train/cmvn.scp scp:- ark:- 
LOG (apply-cmvn[5.3.243~1-e4cd1]:main():apply-cmvn.cc:81) Copied 100 utterances.
LOG (copy-feats[5.3.243~1-e4cd1]:main():copy-feats.cc:143) Copied 100 feature matrices.
... Getting subsets of validation examples for diagnostics and combination.
nnet3-copy-egs ark:- ark,scp:exp/libri-org/nnet3/egs/combine.egs,exp/libri-org/nnet3/egs/combine.scp 
LOG (nnet3-copy-egs[5.3.243~1-e4cd1]:main():nnet3-copy-egs.cc:436) Read 7625 neural-network training examples, wrote 7625, 0 examples had errors.
rm: cannot remove 'exp/libri-org/nnet3/egs/train_combine.scp': No such file or directory
rm: cannot remove 'exp/libri-org/nnet3/egs/valid_combine.scp': No such file or directory
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments and transforms
steps/nnet3/get_egs.sh: Finished preparing training examples
online_ivector_dir =
### MAKE ONE BIG MULTILING EGS DIR ###
steps/nnet3/multilingual/combine_egs.sh --cmd utils/run.pl --samples-per-iter 10000 --lang2weight 0.5,0.5 2 exp/libri-org/nnet3/egs exp/libri-org/nnet3/egs exp/nnet3/multitask/egs
steps/nnet3/multilingual/combine_egs.sh: allocating multilingual examples for training.
steps/nnet3/multilingual/combine_egs.sh: combine combine.scp examples from all langs in exp/nnet3/multitask/egs/combine.scp.
steps/nnet3/multilingual/combine_egs.sh: combine train_diagnostic.scp examples from all langs in exp/nnet3/multitask/egs/train_diagnostic.scp.
steps/nnet3/multilingual/combine_egs.sh: combine valid_diagnostic.scp examples from all langs in exp/nnet3/multitask/egs/valid_diagnostic.scp.
steps/nnet3/multilingual/combine_egs.sh: Finished preparing multilingual training example.
### ================ ###
### BEGIN TRAIN NNET ###
### ================ ###
2018-01-30 17:21:58,286 [steps/nnet3/train_raw_dnn.py:34 - <module> - INFO ] Starting raw DNN trainer (train_raw_dnn.py)
2018-01-30 17:21:58,293 [steps/nnet3/train_raw_dnn.py:181 - train - INFO ] Arguments for the experiment
{'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'utils/run.pl',
 'compute_average_posteriors': False,
 'dir': 'exp/nnet3/multitask',
 'dropout_schedule': None,
 'egs_command': 'queue.pl',
 'egs_dir': 'exp/nnet3/multitask/egs',
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/libri-org/train',
 'final_combination': True,
 'final_effective_lrate': 0.00015,
 'frames_per_eg': 8,
 'image_augmentation_opts': None,
 'initial_effective_lrate': 0.0015,
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_param_change': 2.0,
 'minibatch_size': '256,128',
 'momentum': 0.0,
 'nj': 4,
 'num_epochs': 1.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 1,
 'num_jobs_initial': 1,
 'online_ivector_dir': None,
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 10000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -5,
 'targets_scp': 'exp/libri-org/tri_ali',
 'transform_dir': None,
 'use_dense_targets': False,
 'use_gpu': True}
2018-01-30 17:21:58,298 [steps/libs/nnet3/train/common.py:410 - verify_egs_dir - WARNING ] The ivector ids are not used. It's your responsibility to make sure the ivector extractor has been used consistently
2018-01-30 17:21:58,299 [steps/nnet3/train_raw_dnn.py:294 - train - INFO ] Preparing the initial network.
2018-01-30 17:21:58,367 [steps/nnet3/train_raw_dnn.py:328 - train - INFO ] Training will run for 1.0 epochs = 320 iterations
2018-01-30 17:21:58,368 [steps/libs/nnet3/train/frame_level_objf/common.py:189 - train_one_iteration - INFO ] Training neural net (pass 0)
2018-01-30 17:21:58,371 [steps/libs/nnet3/train/frame_level_objf/common.py:260 - train_one_iteration - INFO ] On iteration 0, learning rate is 0.0015.
run.pl: job failed, log is in exp/nnet3/multitask/log/train.0.1.log
2018-01-30 17:21:58,431 [steps/libs/common.py:170 - background_command_waiter - ERROR ] Command exited with status 1: utils/run.pl --gpu 1 exp/nnet3/multitask/log/train.0.1.log                     nnet3-train   --write-cache=exp/nnet3/multitask/cache.1                       --print-interval=10                     --momentum=0.0                     --max-param-change=1.41421356237                     --backstitch-training-scale=0.0                     --backstitch-training-interval=1                     --srand=0                      "nnet3-copy --learning-rate=0.0015 --scale=1.0 exp/nnet3/multitask/0.raw - |" "ark,bg:nnet3-copy-egs --frame=1 --outputs=ark:exp/nnet3/multitask/egs/egs.output.1.ark --weights=ark:exp/nnet3/multitask/egs/egs.weight.1.ark             scp:exp/nnet3/multitask/egs/egs.1.scp ark:- |             nnet3-shuffle-egs --buffer-size=5000             --srand=0 ark:- ark:- |              nnet3-merge-egs --minibatch-size=128,64 ark:- ark:- |"                     exp/nnet3/multitask/1.1.raw
steps/nnet3/train_raw_dnn.py --stage=-5 --cmd=utils/run.pl --trainer.num-epochs 1 --trainer.optimization.num-jobs-initial=1 --trainer.optimization.num-jobs-final=1 --trainer.optimization.initial-effective-lrate=0.0015 --trainer.optimization.final-effective-lrate=0.00015 --trainer.optimization.minibatch-size=256,128 --trainer.samples-per-iter=10000 --trainer.max-param-change=2.0 --trainer.srand=0 --feat.cmvn-opts=--norm-means=false --norm-vars=false --feat-dir data/libri-org/train --egs.dir exp/nnet3/multitask/egs --use-dense-targets false --targets-scp exp/libri-org/tri_ali --cleanup.remove-egs true --use-gpu true --dir=exp/nnet3/multitask
['steps/nnet3/train_raw_dnn.py', '--stage=-5', '--cmd=utils/run.pl', '--trainer.num-epochs', '1', '--trainer.optimization.num-jobs-initial=1', '--trainer.optimization.num-jobs-final=1', '--trainer.optimization.initial-effective-lrate=0.0015', '--trainer.optimization.final-effective-lrate=0.00015', '--trainer.optimization.minibatch-size=256,128', '--trainer.samples-per-iter=10000', '--trainer.max-param-change=2.0', '--trainer.srand=0', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--feat-dir', 'data/libri-org/train', '--egs.dir', 'exp/nnet3/multitask/egs', '--use-dense-targets', 'false', '--targets-scp', 'exp/libri-org/tri_ali', '--cleanup.remove-egs', 'true', '--use-gpu', 'true', '--dir=exp/nnet3/multitask']
use_multitask_egs=True
